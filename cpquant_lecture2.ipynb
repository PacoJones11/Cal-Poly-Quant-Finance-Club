{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktSI7h-fBVv4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "787340ca-ae22-4c6b-a306-3273a82bb892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cpquant\n",
            "  Downloading cpquant-0.1.5-py3-none-any.whl (9.1 kB)\n",
            "Collecting blinker\n",
            "  Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting appnope==0.1.3 (from cpquant)\n",
            "  Downloading appnope-0.1.3-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting asttokens==2.2.1 (from cpquant)\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting backcall==0.2.0 (from cpquant)\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting bleach==6.0.0 (from cpquant)\n",
            "  Downloading bleach-6.0.0-py3-none-any.whl (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.5/162.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blinker\n",
            "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Collecting certifi==2023.5.7 (from cpquant)\n",
            "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.0/157.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer==3.1.0 (from cpquant)\n",
            "  Downloading charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click==8.1.7 (from cpquant)\n",
            "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy==1.0.7 (from cpquant)\n",
            "  Downloading contourpy-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.11.0 (from cpquant)\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting decorator==5.1.1 (from cpquant)\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting docutils==0.20.1 (from cpquant)\n",
            "  Downloading docutils-0.20.1-py3-none-any.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting executing==1.2.0 (from cpquant)\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting flask==3.0.0 (from cpquant)\n",
            "  Downloading flask-3.0.0-py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools==4.39.4 (from cpquant)\n",
            "  Downloading fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==3.4 (from cpquant)\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ijson==3.2.1 (from cpquant)\n",
            "  Downloading ijson-3.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (113 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.1/113.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata==6.6.0 (from cpquant)\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Collecting ipython==8.14.0 (from cpquant)\n",
            "  Downloading ipython-8.14.0-py3-none-any.whl (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.7/798.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting itsdangerous==2.1.2 (from cpquant)\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Collecting jaraco-classes==3.2.3 (from cpquant)\n",
            "  Downloading jaraco.classes-3.2.3-py3-none-any.whl (6.0 kB)\n",
            "Collecting jedi==0.18.2 (from cpquant)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2==3.1.2 (from cpquant)\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keyring==23.13.1 (from cpquant)\n",
            "  Downloading keyring-23.13.1-py3-none-any.whl (37 kB)\n",
            "Collecting kiwisolver==1.4.4 (from cpquant)\n",
            "  Downloading kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown-it-py==2.2.0 (from cpquant)\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markupsafe==2.1.3 (from cpquant)\n",
            "  Downloading MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting matplotlib==3.7.1 (from cpquant)\n",
            "  Downloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline==0.1.6 (from cpquant)\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting mdurl==0.1.2 (from cpquant)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting more-itertools==9.1.0 (from cpquant)\n",
            "  Downloading more_itertools-9.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msgpack==1.0.5 (from cpquant)\n",
            "  Downloading msgpack-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.8/316.8 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.24.3 (from cpquant)\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==23.1 (from cpquant)\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==1.5.3 (from cpquant)\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parso==0.8.3 (from cpquant)\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pexpect==4.8.0 (from cpquant)\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pickleshare==0.7.5 (from cpquant)\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting pillow==9.5.0 (from cpquant)\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pkginfo==1.9.6 (from cpquant)\n",
            "  Downloading pkginfo-1.9.6-py3-none-any.whl (30 kB)\n",
            "Collecting plotly==5.14.1 (from cpquant)\n",
            "  Downloading plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prompt-toolkit==3.0.38 (from cpquant)\n",
            "  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil==5.9.5 (from cpquant)\n",
            "  Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.1/282.1 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess==0.7.0 (from cpquant)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting pure-eval==0.2.2 (from cpquant)\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting pydantic==1.10.8 (from cpquant)\n",
            "  Downloading pydantic-1.10.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments==2.15.1 (from cpquant)\n",
            "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing==3.0.9 (from cpquant)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil==2.8.2 (from cpquant)\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv==1.0.0 (from cpquant)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting pytz==2023.3 (from cpquant)\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting readme-renderer==37.3 (from cpquant)\n",
            "  Downloading readme_renderer-37.3-py3-none-any.whl (14 kB)\n",
            "Collecting requests==2.31.0 (from cpquant)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt==1.0.0 (from cpquant)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986==2.0.0 (from cpquant)\n",
            "  Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting rich==13.4.1 (from cpquant)\n",
            "  Downloading rich-13.4.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seaborn==0.12.2 (from cpquant)\n",
            "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six==1.16.0 (from cpquant)\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting sseclient-py==1.7.2 (from cpquant)\n",
            "  Downloading sseclient_py-1.7.2-py2.py3-none-any.whl (8.4 kB)\n",
            "Collecting stack-data==0.6.2 (from cpquant)\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting tenacity==8.2.2 (from cpquant)\n",
            "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
            "Collecting tqdm==4.65.0 (from cpquant)\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traitlets==5.9.0 (from cpquant)\n",
            "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting twine==4.0.2 (from cpquant)\n",
            "  Downloading twine-4.0.2-py3-none-any.whl (36 kB)\n",
            "Collecting typing-extensions==4.6.3 (from cpquant)\n",
            "  Downloading typing_extensions-4.6.3-py3-none-any.whl (31 kB)\n",
            "Collecting urllib3==2.0.2 (from cpquant)\n",
            "  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.2/123.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wcwidth==0.2.6 (from cpquant)\n",
            "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Collecting webencodings==0.5.1 (from cpquant)\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting websockets==11.0.3 (from cpquant)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug==3.0.0 (from cpquant)\n",
            "  Downloading werkzeug-3.0.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.6/226.6 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wget==3.2 (from cpquant)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zipp==3.15.0 (from cpquant)\n",
            "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Collecting SecretStorage>=3.2 (from keyring==23.13.1->cpquant)\n",
            "  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
            "Collecting jeepney>=0.4.2 (from keyring==23.13.1->cpquant)\n",
            "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cryptography>=2.0 (from SecretStorage>=3.2->keyring==23.13.1->cpquant)\n",
            "  Downloading cryptography-41.0.7-cp37-abi3-manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cffi>=1.12 (from cryptography>=2.0->SecretStorage>=3.2->keyring==23.13.1->cpquant)\n",
            "  Downloading cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.9/443.9 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycparser (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring==23.13.1->cpquant)\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=d9a8cee456dad56c923233ce559d565e9c53165b4dd16480495b23c014675547\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, webencodings, wcwidth, sseclient-py, pytz, pure-eval, ptyprocess, pickleshare, msgpack, ijson, executing, backcall, appnope, zipp, websockets, urllib3, typing-extensions, traitlets, tqdm, tenacity, six, rfc3986, python-dotenv, pyparsing, pygments, pycparser, psutil, prompt-toolkit, pkginfo, pillow, pexpect, parso, packaging, numpy, more-itertools, mdurl, markupsafe, kiwisolver, jeepney, itsdangerous, idna, fonttools, docutils, decorator, cycler, click, charset-normalizer, certifi, blinker, werkzeug, requests, python-dateutil, pydantic, plotly, matplotlib-inline, markdown-it-py, jinja2, jedi, jaraco-classes, importlib-metadata, contourpy, cffi, bleach, asttokens, stack-data, rich, requests-toolbelt, readme-renderer, pandas, matplotlib, flask, cryptography, SecretStorage, seaborn, ipython, keyring, twine, cpquant\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "sphinx 5.0.2 requires docutils<0.19,>=0.14, but you have docutils 0.20.1 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.14.0 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SecretStorage-3.3.3 appnope-0.1.3 asttokens-2.2.1 backcall-0.2.0 bleach-6.0.0 blinker-1.6.2 certifi-2023.11.17 cffi-1.16.0 charset-normalizer-3.1.0 click-8.1.7 contourpy-1.0.7 cpquant-0.1.5 cryptography-41.0.7 cycler-0.11.0 decorator-4.4.2 docutils-0.18.1 executing-1.2.0 flask-2.2.5 fonttools-4.39.4 idna-3.4 ijson-3.2.1 importlib-metadata-6.6.0 ipython-7.34.0 itsdangerous-2.1.2 jaraco-classes-3.2.3 jedi-0.18.2 jeepney-0.8.0 jinja2-3.1.2 keyring-23.13.1 kiwisolver-1.4.4 markdown-it-py-2.2.0 markupsafe-2.1.3 matplotlib-3.7.1 matplotlib-inline-0.1.6 mdurl-0.1.2 more-itertools-10.1.0 msgpack-1.0.5 numpy-1.23.5 packaging-23.1 pandas-1.5.3 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pillow-9.4.0 pkginfo-1.9.6 plotly-5.14.1 prompt-toolkit-3.0.38 psutil-5.9.5 ptyprocess-0.7.0 pure-eval-0.2.2 pycparser-2.21 pydantic-1.10.13 pygments-2.15.1 pyparsing-3.0.9 python-dateutil-2.8.2 python-dotenv-1.0.0 pytz-2023.3 readme-renderer-37.3 requests-2.31.0 requests-toolbelt-1.0.0 rfc3986-2.0.0 rich-13.4.1 seaborn-0.12.2 six-1.16.0 sseclient-py-1.7.2 stack-data-0.6.2 tenacity-8.2.2 tqdm-4.65.0 traitlets-5.7.1 twine-4.0.2 typing-extensions-4.5.0 urllib3-2.0.2 wcwidth-0.2.13 webencodings-0.5.1 websockets-11.0.3 werkzeug-3.0.0 wget-3.2 zipp-3.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "PIL",
                  "certifi",
                  "cffi",
                  "cycler",
                  "dateutil",
                  "decorator",
                  "kiwisolver",
                  "matplotlib",
                  "matplotlib_inline",
                  "mpl_toolkits",
                  "numpy",
                  "pexpect",
                  "pickleshare",
                  "prompt_toolkit",
                  "psutil",
                  "pygments",
                  "six",
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Setup\n",
        "!pip install cpquant --ignore-installed blinker\n",
        "# Import and set environment vars\n",
        "import pandas as pd\n",
        "from cpquant.data import AlpacaDataClient\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"ALPACA_DATA_PUBLIC_KEY\"] = \"AKZS8A4U96H2NUFJRGCV\"\n",
        "os.environ[\"ALPACA_DATA_SECRET_KEY\"] = \"w6mkp6JeLbLMp5AVMKtviFEyubggFJvkjgsVMApA\"\n",
        "os.environ[\"ALPACA_TRADE_PUBLIC_KEY\"] = \"AKE4BDS0VAJHCTWA0YUO\"\n",
        "os.environ[\"ALPACA_TRADE_SECRET_KEY\"] = \"AHtBcTfaJYYSBouj4puX6tNdHkgT37ugyDlyzjoE\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This lecture will focus on the financial data that we will be using throughout this intro course. There are many different types of financial data, but for our purposes we will focus on stock \"tick\" data.\n",
        "\n",
        "\n",
        "Before we continue, I must define what a ***tick*** is. A tick is simply a transaction of shares between two parties, it is also often reffered to as a \"trade\". I may use these terms interchangeably.\n",
        "A tick consists of three things:\n",
        "\n",
        "\n",
        "1.   Stock that is traded (Often called a ***ticker*** i.e. TSLA, AAPL)\n",
        "2.   The ***price*** that the stock is traded at\n",
        "3.   The ***quantity*** of shares that were traded\n",
        "\n",
        "\n",
        "The primary \"data structure\" that we will use is called a ***bar***\n",
        "A traditional bar *bar* is a sampling of some ticks, over a given time. There exists other types of bars, but we will focus on ***time bars***, such as Minute Bars, Hour Bars, Day Bars, and Week Bars. Each bar aggregates ticks for different periods of time.\n",
        "A bar consists of 5 datapoints:\n",
        "\n",
        "1.   **Open price** (the price of the first tick included in the bar)\n",
        "2.   **Close price** (the price of the last tick included in the bar)\n",
        "3.   **High price** (the price of the \"most expensive\" tick in the bar)\n",
        "4.   **Low price** (the price of the \"lease expensive\" tick in the bar)\n",
        "5.   **Volume** (the total quantity of shares traded in the bar, sum of all tick quantities)\n",
        "\n",
        "Bars are often displayed visually as ***candlesticks***\n",
        "\n",
        "\n",
        "![download.png](data:image/png;base64,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)\n",
        "\n",
        "You will notice that volume is missing from the candlestick, usually volume is displayed as a histogram at the bottom of the chart, as it has different units from everything else in the bar. You will also notice that if the close price is higher than the open price, the bar will be colored green, indicating the stock rose over time. Similarily if open > close, the bar will be red."
      ],
      "metadata": {
        "id": "fto5POvsBeJQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets pull some tick data from cpquant utilizing the get_trades() function. Ignore the indexing at the end of the function, get_trades() is a complex cpquant function and likely wont be used outside fo this lecture."
      ],
      "metadata": {
        "id": "1ySYKft9OnEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trades = client.get_trades([\"AAPL\"], start=\"2023-10-10\", end=\"2023-10-11\", limit=10000)[0][\"AAPL\"]\n",
        "trades"
      ],
      "metadata": {
        "id": "gyAIW7mAO8WL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "73ae9a52-e252-4b06-c272-87d669c57bb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'client' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-eeb65b6cb824>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrades\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trades\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"AAPL\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2023-10-10\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2023-10-11\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"AAPL\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrades\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that trades is a pandas DataFrame. You can see that trades are much higher granularity than bars (some trades are even happening milliseconds between eachother). You will also notice that there are columns that we do not care about (condition, trade_id, exchange_code, & exchange), lets drop them."
      ],
      "metadata": {
        "id": "DIWACtYPPePX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trades = trades.drop(columns=[\"condition\", \"trade_id\", \"exchange_code\", \"exchange\"])\n",
        "trades"
      ],
      "metadata": {
        "id": "kbJ97C9KPzRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, utilzing the trades data, we will construct a set of 5-Minute *bars*.\n",
        "\n",
        "I'm doing a little bit of pandas \"black magic\" in this cell, I will explain it, but do not worry if you do not fully understand this, it will be abstracted away later."
      ],
      "metadata": {
        "id": "97zN6IpSP8Rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime # datetime is a python library for dealing with times\n",
        "def get_5_minute_chunk(time): # This is a function that takes as input a datetime object, and returns a unique identifer depending on what \"5-minute chunk\" it belongs to\n",
        "  epoch = datetime.datetime.utcfromtimestamp(0) # If you are unfamilar with the conecpt of the epoch, its just the first millisecond recognized in all computers\n",
        "  # We subtract the epoch from our current time, and get the total number of seconds, this gives each second in history a unique number\n",
        "  return (time - epoch).total_seconds() // (60*5) # We then divide by 60*5, to give each \"5-minute chunk\" its own unique identifer.\n",
        "  #  If two timestamps are within 5 minutes of eachother, this function will return the same value\n",
        "# We then create a new column in the trades dataframe, with the results of the above function on each timestamp\n",
        "trades[\"5_minute_chunk\"] = trades.index.to_series().apply(get_5_minute_chunk)\n",
        "trades"
      ],
      "metadata": {
        "id": "EMXvxn_8QE7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some more black magic"
      ],
      "metadata": {
        "id": "xcjO5L9uWx8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# groupby is a powerful pandas function, if you are familiar with SQL (CSC 365) it is analogous to the SQL GROUP BY\n",
        "# Here we are grouping by the new column we just created, which results in a list of \"chunks\" of data, such that each chunk shares a \"5-minute chunk\"\n",
        "groups = trades.groupby(\"5_minute_chunk\")\n",
        "# Initialize an array to store our calculated dataa\n",
        "bars = []\n",
        "# We begin iterating over all the groups\n",
        "for group, data in groups:\n",
        "  # We grab the timestamp of the first trade, here we call .name instead of .index because of how the groupby function works\n",
        "  first_ms = data.iloc[0].name\n",
        "  # We then process the timestamp by removing all second/millisecond data from it (datetime objects are immutable so I have to create a new one)\n",
        "  time = datetime.datetime(first_ms.year, first_ms.month, first_ms.day, first_ms.hour, first_ms.minute)\n",
        "  open = data.iloc[0][\"price\"] # Calculate the opening price, the first trade price\n",
        "  close = data.iloc[-1][\"price\"] # Calculate the closing price, the last trade price\n",
        "  high = max(data[\"price\"]) # Calculate the high\n",
        "  low = min(data[\"price\"]) # Calculate the low\n",
        "  volume = data[\"size\"].sum() # Calculate the volume\n",
        "  bars.append({\"time\": time, \"open\": open, \"close\": close, \"high\": high, \"low\": low, \"volume\": volume}) # Insert that data into our list\n",
        "df = pd.DataFrame(bars) # Create a new dataframe\n",
        "df.index = df[\"time\"] # Set the index to the time column\n",
        "df = df.drop(columns=[\"time\"]) # Drop the redundant time column\n",
        "df\n"
      ],
      "metadata": {
        "id": "Eu18awVXTqc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now see that df is a DataFrame containing the aggregated bar data.\n",
        "You may be curious why some of the time columns are not perfect 5 minute increments. This is due to \"holes\" in our data, such that the first bar of the next five minute chunk is in the 2nd or 3rd minute of the 5 minute chunk. You'll see this is more common twoards the front of the DataFrame, as this is pre-market time, and thus there are less people trading, it clears up near the end."
      ],
      "metadata": {
        "id": "2mH2RQ1AW1Z4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets pull some data from cpquant to look at some bars. We are going to initiate a AlpacaDataClient object (imported from cpquant) and call the get_bars() method to grab the stock data for AAPL. Later I will go into depth about this important function."
      ],
      "metadata": {
        "id": "P7XwA5ToMuBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    client = AlpacaDataClient()\n",
        "    bars = client.get_bars(\"AAPL\", start=\"2021-01-01\")[\"AAPL\"]\n",
        "    bars"
      ],
      "metadata": {
        "id": "kFPPD-chBc1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that *bars* is a pandas DataFrame. Additionally, this is a set of day bars (as indicated by the time index column) & it includes two feilds not previously mentioned, trades & volume weighted. Trades is simply the number of trades included in the bar, and volume weighted is outside of this lectures scope. Lets drop them."
      ],
      "metadata": {
        "id": "VtVsDoi7N1n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bars = bars.drop(columns=[\"trades\", \"volume weighted\"]) #.drop() removes the specified columns from the dataframe\n",
        "bars"
      ],
      "metadata": {
        "id": "rNf4uT8mN072"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see how much less work it is to just call the cpquant library function for creating bars. Additionally, if you were to try to create bars from the ticks for 4 years, you would likely overload the amount of memory your computer has due to the sheer number of ticks that are generated.\n",
        "\n",
        "Lets now try to visualzie the data as a candlestick chart"
      ],
      "metadata": {
        "id": "9qJv_GGqZvZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We are going to use the plotly library, rather than create our own graphing funciton\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure(data=[go.Candlestick(x=bars.index,\n",
        "                open=bars['open'],\n",
        "                high=bars['high'],\n",
        "                low=bars['low'],\n",
        "                close=bars['close'])])\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "GSaw1ERubOHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotly is a wonderful graphing library, slightly more complex than matplotlib, but offers much more features. Play around with the chart to see its utility.\n",
        "\n",
        "The amount of data we have is a bit much to use a candlestick chart on, usually I would reccomend just plotting the close price."
      ],
      "metadata": {
        "id": "SZzwkrA4cCmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets learn a little more about the get_bars() function:\n",
        "\n",
        "Here is the prototype for the function\n",
        "\n",
        "\n",
        "```\n",
        " get_bars(self, symbols, timeframe=\"1D\", start=None, end=None, adjustment=\"raw\", limit=1000, asof=None, feed=\"iex\", currency=\"USD\", page_token=None, only_market=False):\n",
        "```\n",
        "\n",
        "Theres a lot of inputs, so lets break it down:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "            Retrieves historical bars for one or more symbols.\n",
        "\n",
        "            Args:\n",
        "                symbols (list): A list of symbols to retrieve bars for.\n",
        "                timeframe (str): The timeframe for the bars. Default is \"1D\".   \n",
        "                  You can use the following values:\n",
        "                  [1-59]Min / T\n",
        "                  [1-23]Hour / H\n",
        "                  1Day / D\n",
        "                  1Week / W\n",
        "                  [1,2,3,4,6,12]Month / M\n",
        "                start (str): The start date for the bars in \"YYYY-MM-DD\" format. Default is None.\n",
        "                end (str): The end date for the bars in \"YYYY-MM-DD\" format. Default is None.\n",
        "                adjustment (str): The adjustment method for the bars. Default is \"raw\".\n",
        "                limit (int): The maximum number of bars to retrieve. Default is 1000.\n",
        "                asof (str): The date to retrieve bars as of in \"YYYY-MM-DD\" format. Default is None.\n",
        "                feed (str): The data feed to retrieve bars from. Default is \"iex\", can also be \"sip\".\n",
        "                currency (str): The currency to retrieve bars in. Default is \"USD\".\n",
        "                page_token (str): The page token to retrieve the next page of bars. Default is None.\n",
        "                only_market (bool): Whether to only retrieve bars for market hours. Default is False.\n",
        "\n",
        "            Returns:\n",
        "                dict: A dictionary containing the bars data for the requested symbols.\n",
        "```\n",
        "\n",
        "The important inputs to take note of are\n",
        "\n",
        "\n",
        "1.   symbols -> a list of tickers [\"AAPL\", \"TSLA\"]\n",
        "2.   timeframe -> the granularity of the bars\n",
        "3.   start -> when the start of the data is, defaults to a year ago\n",
        "4.   end -> when the data stops, defaults to now\n",
        "\n",
        "The function will return a dictionary, with keys as the tickers, and values as the dataframe containing the data. i.e. providing the fucntion with [\"AAPL\", \"TSLA\"] it will return a dictionary as such\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "{\"AAPL\": **Pandas DataFrame**,\n",
        " \"TSLA\": **Pandas DataFrame**}\n",
        "\n",
        " # To access it\n",
        " data = client.get_bars([\"AAPL\", \"TSLA\"])\n",
        " apple_data = data[\"AAPL\"]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iKJbj33Ecx3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practice Problems\n",
        "\n",
        "\n",
        "\n",
        "1.   Query 5 minute bars for the whole month of October for Apple (AAPL) Tesla (TSLA) Coke (KO) & Lockheed Martin (LMT)\n",
        "2.   Which stock had the highest volume?\n",
        "3.   Which stock had the greatest returns for the month of October?\n",
        "4.   Which stock had the highest relative price increase at any point?\n",
        "5.   Which stock had the lowest relative return?\n",
        "6.   Create a script that allows the user to view a daily candlestick chart for the past year for any stock (use the input function)\n",
        "7.   *(Challenge)* Create 1 minute bars from tick level data\n",
        "\n"
      ],
      "metadata": {
        "id": "01ANseJmo3Gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1: Query 5 minute bars for the whole month of October for Apple (AAPL) Tesla (TSLA) Coke (KO) & Lockheed Martin (LMT)\n",
        "data = client.get_bars(symbols=[\"AAPL\", \"TSLA\", \"KO\", \"LMT\"], timeframe=\"5T\", start=\"2023-10-01\", end=\"2023-10-31\", limit=100000)\n",
        "data"
      ],
      "metadata": {
        "id": "FM-wF7-sb3pc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}